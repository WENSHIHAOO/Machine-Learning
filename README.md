# Machine-Learning

This repository contains notes, materials, and explanations for a machine learning course, covering foundational concepts to advanced topics. The course is structured as follows:

---

## 1. Simple Tools and Bayes
**Topics**: Point estimation, Bayes classifier, Naive Bayes  
**Summary**:  
- Point estimation techniques such as Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP).  
- The Bayes classifier as an optimal probabilistic decision rule.  
- Naive Bayes classifier, assuming conditional independence among features, for efficient and scalable classification.

---

## 2. Margin-Based Methods
**Topics**: Logistic regression, linear regression, convex optimization, max margin classifier  
**Summary**:  
- Logistic regression and its sigmoid function for binary classification.  
- Linear regression through least squares minimization and its probabilistic interpretation.  
- Convex optimization for solving classification and regression tasks.  
- Max margin classifiers as the foundation of Support Vector Machines (SVMs).

---

## 3. Tree-Based Methods
**Topics**: Decision trees, bagging, boosting  
**Summary**:  
- Decision trees for non-parametric, interpretable data partitioning.  
- Bagging (Bootstrap Aggregating) to reduce variance using ensemble methods.  
- Boosting techniques like AdaBoost that iteratively combine weak classifiers to form strong models.

---

## 4. Generative Models
**Topics**: K-means, Gaussian Mixture Models (GMM), graphical models, Hidden Markov Models (HMM)  
**Summary**:  
- K-means for clustering using distance-based partitions.  
- GMMs for probabilistic clustering via Gaussian distributions.  
- Graphical models for representing dependencies between random variables.  
- HMMs for modeling sequential data with hidden states and observed emissions.

---

## 5. Dimensionality Reduction
**Topics**: Recommender systems, PCA, ICA, LDA  
**Summary**:  
- PCA (Principal Component Analysis) for projecting data onto principal axes of variance.  
- ICA (Independent Component Analysis) for discovering statistically independent features.  
- LDA (Linear Discriminant Analysis) for supervised dimensionality reduction.  
- Matrix factorization techniques for building recommender systems.

---

## 6. Support Vector Machines (SVM)
**Topics**: Duality, dual SVM, kernels  
**Summary**:  
- Dual SVM formulation using Lagrangian multipliers for optimization.  
- Kernel functions (e.g., RBF kernel, polynomial kernel) to handle non-linear decision boundaries.  
- Margin maximization as a robust principle for classification.

---

## 7. Advanced Topics
**Topics**: Deep learning, online optimization, learning theory  
**Summary**:  
- Deep learning and neural networks for hierarchical learning in complex tasks.  
- Online optimization methods like stochastic gradient descent for large-scale real-time learning.  
- Learning theory concepts such as PAC learning and generalization error bounds for theoretical guarantees.
